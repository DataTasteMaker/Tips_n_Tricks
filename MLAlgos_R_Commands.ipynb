{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 popular machine learning algorithms and related R commands\n",
    "\n",
    "\n",
    "1. Linear regression\n",
    "2. Logistic Regression\n",
    "3. K-Means Clustering\n",
    "4. K-Nearest Neighbours (KNN) Classification\n",
    "5. Naive Bayes Classification\n",
    "6. Decision Trees\n",
    "7. Support Vector Machine (SVM)\n",
    "8. Artificial Neural Network (ANN)\n",
    "9. Apriori\n",
    "10. AdaBoost\n",
    "\n",
    "\n",
    "* <b>Linear regression</b>: \"lm\" method from base package could be used for linear regression models.\n",
    "\n",
    "<code> <font color = \"blue\"> lreg_model <- lm(y ~ x1 + x2, data=as.data.frame(cbind(y,x1,x2))) </font> </code>\n",
    "\n",
    "* <b>Logistic Regression</b>: Logistic regression is a classification based model. \"glm\" method from base R package could be used for logistic regression.\n",
    "\n",
    "<code> <font color = \"blue\"> logitreg_model <- glm(y ~ x1+x2, family=binomial(link=\"logit\"),  data=as.data.frame(cbind(y,x1,x2)))  </font> </code>\n",
    "\n",
    "* <b>K-Means Clustering</b>: \"kmeans\" method from base R package could be used to run k-means clustering. Following is a sample command given X is a data matrix and m is the number of clusters\n",
    "\n",
    "<code> <font color = \"blue\"> kmeans_model <- kmeans(x=X, centers=m)  </font> </code>\n",
    "\n",
    "* <b>K-Nearest Neighbors (KNN) Classification</b>: \"knn\" method from \"class\" package could be used for K-NN modeling. One need to install and load \"class\" package. Following is the sample command given X_train represents a training dataset, X_test represents test data set, k represents number of nearest neighbors to be included for the modeling\n",
    "\n",
    "<code> <font color = \"blue\"> knnclass_model <- knn(train=X_train, test=X_test, cl=as.factor(labels), k=K)  </font> </code>\n",
    "\n",
    "* <b>Naive Bayes Classification</b>: \"naiveBayes\" method from \"e1071\" package could be used for Naive Bayes classification. One need to install and load \"e1071\" package prior to analysis.\n",
    "\n",
    "<code> <font color = \"blue\"> NaiveBayes_model <- naiveBayes(y ~ x1 + x2, data=as.data.frame(cbind(y,x1,x2)))  </font> </code>\n",
    "\n",
    "* <b>Decision Trees</b>: \"rpart\" method from \"rpart\" can be used for Decision Trees. One need to install and load \"rpart\" package.\n",
    "\n",
    "<code> <font color = \"blue\"> DTree <- rpart(y ~ x1 + x2, data=as.data.frame(cbind(y,x1,x2)), method=\"class\")  </font> </code>\n",
    "\n",
    "* <b>Support Vector Machine (SVM)</b>: \"svm\" method from \"e1071\" package could be used for SVM. Note that the same package also provide method, naiveBayes, for Naive Bayes classification. One need to install and load \"e1071\" package. Following is the sample command given X is the matrix of features, labels be the vector of 0-1 class labels, and C being regularization parameter\n",
    "\n",
    "<code> <font color = \"blue\"> svm_model <- svm(x=X, y=as.factor(labels), kernel =\"radial\", cost=C) </font> </code>\n",
    "\n",
    "* <b>Artifical Neural Network (ANN)</b>: \"neuralnet\" method from \"neuralnet\" package could be used for ANN modeling. Following is sample command:\n",
    "\n",
    "<code> <font color = \"blue\"> ann_model <- neuralnet( y ~ x1 + x2 + x3, data=as.data.frame(cbind(y,x1,x2, x3)), hidden = 1)  </font> </code>\n",
    "\n",
    "Prediction could be made using following formula:\n",
    "\n",
    "<code> <font color = \"blue\"> predict <- compute( ann_model, as.data.frame(cbind(x1,x2)) )  </font> </code>\n",
    "\n",
    "* <b>Apriori</b>: \"apriori\" method from \"arules\" package could be used for Apriori analysis. One need to install and load \"arules\" package.\n",
    "\n",
    "<code> <font color = \"blue\"> apriori_model <- apriori(as.matrix(sampleDataset), parameter = list(supp = 0.8, conf = 0.9))  </font> </code>\n",
    "\n",
    "* <b>AdaBoost</b>: \"ada\" method from \"rpart\" package could be used as boosting function. Following is sample command:\n",
    "\n",
    "<code> <font color = \"blue\"> Adaboost_model <- ada(x=X, y=labels)  </font> </code>\n",
    "\n",
    "For most of the above formulas including linear regression model, one could use following function to predict:\n",
    "\n",
    "<code> <font color = \"blue\"> predicted_values <- predict(some_model, newdata=as.data.frame(cbind(x1_test, x2_test))) </font> </code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
